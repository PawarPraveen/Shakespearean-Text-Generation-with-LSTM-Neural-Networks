{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM1Q2ZZx6hMU",
        "outputId": "a8fa7fbb-0fee-4a63-d11b-013a81704e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU Available: True\n"
          ]
        }
      ],
      "source": [
        "# Essential installations\n",
        "!pip install -q nltk tensorflow\n",
        "\n",
        "# Import with optimization\n",
        "import nltk\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configure for maximum performance\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')  # Faster training\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", bool(physical_devices))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Data Loading & Cleaning\n",
        "nltk.download('gutenberg', quiet=True)\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "text = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "text = re.sub(r'[^a-zA-Z\\s\\.,!?;\\':-]', '', text)\n",
        "text = text.lower()\n",
        "text = re.sub(r'\\s+', ' ', text).strip()"
      ],
      "metadata": {
        "id": "y408WURC6xYY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {char: i for i, char in enumerate(chars)}\n",
        "int_to_char = {i: char for i, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "NYVaesk_7H2C"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 25\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LENGTH):\n",
        "    sequences.append([char_to_int[char] for char in text[i:i + SEQ_LENGTH]])\n",
        "    next_chars.append(char_to_int[text[i + SEQ_LENGTH]])\n",
        "\n",
        "X = np.array(sequences)\n",
        "y = np.array(next_chars)\n"
      ],
      "metadata": {
        "id": "73Htt29g7Tkx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(len(chars), 64, input_length=SEQ_LENGTH),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(len(chars), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "7T9kCiQ87fmp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Zi-hfFvw7wf-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "split_idx = int(0.9 * len(X))\n",
        "X_train, X_val = X[:split_idx], X[split_idx:]\n",
        "y_train, y_val = y[:split_idx], y[split_idx:]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=256,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[\n",
        "        EarlyStopping(patience=10, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyHPAxXXFZEV",
        "outputId": "5e50cc31-c1bf-4614-f5a6-266db0baaff9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.1879 - loss: 2.9500 - val_accuracy: 0.3230 - val_loss: 2.3150 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3217 - loss: 2.3358 - val_accuracy: 0.3619 - val_loss: 2.1333 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.3605 - loss: 2.1794 - val_accuracy: 0.4046 - val_loss: 2.0274 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3893 - loss: 2.0761 - val_accuracy: 0.4242 - val_loss: 1.9414 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.4076 - loss: 2.0089 - val_accuracy: 0.4406 - val_loss: 1.8765 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4233 - loss: 1.9449 - val_accuracy: 0.4538 - val_loss: 1.8309 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4343 - loss: 1.9040 - val_accuracy: 0.4631 - val_loss: 1.7981 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.4439 - loss: 1.8709 - val_accuracy: 0.4712 - val_loss: 1.7722 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4488 - loss: 1.8413 - val_accuracy: 0.4738 - val_loss: 1.7498 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.4550 - loss: 1.8224 - val_accuracy: 0.4816 - val_loss: 1.7300 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4603 - loss: 1.8040 - val_accuracy: 0.4852 - val_loss: 1.7159 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4648 - loss: 1.7770 - val_accuracy: 0.4870 - val_loss: 1.7084 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.4736 - loss: 1.7599 - val_accuracy: 0.4895 - val_loss: 1.6932 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4716 - loss: 1.7513 - val_accuracy: 0.4941 - val_loss: 1.6840 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.4744 - loss: 1.7402 - val_accuracy: 0.4980 - val_loss: 1.6705 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4788 - loss: 1.7301 - val_accuracy: 0.5013 - val_loss: 1.6629 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4817 - loss: 1.7172 - val_accuracy: 0.5019 - val_loss: 1.6567 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.4826 - loss: 1.7086 - val_accuracy: 0.5029 - val_loss: 1.6481 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4882 - loss: 1.6941 - val_accuracy: 0.5051 - val_loss: 1.6450 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4904 - loss: 1.6858 - val_accuracy: 0.5061 - val_loss: 1.6393 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4902 - loss: 1.6844 - val_accuracy: 0.5065 - val_loss: 1.6390 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.4955 - loss: 1.6662 - val_accuracy: 0.5075 - val_loss: 1.6311 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4950 - loss: 1.6649 - val_accuracy: 0.5093 - val_loss: 1.6246 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.4963 - loss: 1.6547 - val_accuracy: 0.5086 - val_loss: 1.6234 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.4982 - loss: 1.6518 - val_accuracy: 0.5117 - val_loss: 1.6198 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5003 - loss: 1.6481 - val_accuracy: 0.5136 - val_loss: 1.6144 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.5029 - loss: 1.6385 - val_accuracy: 0.5126 - val_loss: 1.6139 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5018 - loss: 1.6393 - val_accuracy: 0.5129 - val_loss: 1.6109 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5033 - loss: 1.6288 - val_accuracy: 0.5137 - val_loss: 1.6080 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.5066 - loss: 1.6213 - val_accuracy: 0.5161 - val_loss: 1.6038 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5071 - loss: 1.6173 - val_accuracy: 0.5172 - val_loss: 1.6024 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5058 - loss: 1.6157 - val_accuracy: 0.5167 - val_loss: 1.6034 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.5079 - loss: 1.6115 - val_accuracy: 0.5194 - val_loss: 1.5982 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5096 - loss: 1.6054 - val_accuracy: 0.5196 - val_loss: 1.5985 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5106 - loss: 1.6005 - val_accuracy: 0.5199 - val_loss: 1.5954 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5103 - loss: 1.6011 - val_accuracy: 0.5218 - val_loss: 1.5964 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5125 - loss: 1.5959 - val_accuracy: 0.5201 - val_loss: 1.5922 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.5121 - loss: 1.5934 - val_accuracy: 0.5198 - val_loss: 1.5893 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5136 - loss: 1.5868 - val_accuracy: 0.5228 - val_loss: 1.5901 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5159 - loss: 1.5873 - val_accuracy: 0.5217 - val_loss: 1.5916 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5133 - loss: 1.5834 - val_accuracy: 0.5226 - val_loss: 1.5888 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.5163 - loss: 1.5778 - val_accuracy: 0.5228 - val_loss: 1.5901 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5184 - loss: 1.5686 - val_accuracy: 0.5227 - val_loss: 1.5876 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.5182 - loss: 1.5647 - val_accuracy: 0.5219 - val_loss: 1.5886 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.5208 - loss: 1.5641 - val_accuracy: 0.5223 - val_loss: 1.5850 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.5220 - loss: 1.5621 - val_accuracy: 0.5225 - val_loss: 1.5847 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5196 - loss: 1.5660 - val_accuracy: 0.5255 - val_loss: 1.5913 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5217 - loss: 1.5545 - val_accuracy: 0.5232 - val_loss: 1.5873 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.5214 - loss: 1.5590 - val_accuracy: 0.5252 - val_loss: 1.5895 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 1.5508 - val_accuracy: 0.5240 - val_loss: 1.5915 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, num_chars=100, temperature=0.8):\n",
        "    generated = seed_text\n",
        "    current_seq = seed_text[-SEQ_LENGTH:]\n",
        "\n",
        "    for i in range(num_chars):\n",
        "        # Convert to integers\n",
        "        x_seq = []\n",
        "        for char in current_seq:\n",
        "            if char in char_to_int:\n",
        "                x_seq.append(char_to_int[char])\n",
        "            else:\n",
        "                x_seq.append(0)  # Default for unknown chars\n",
        "\n",
        "        if len(x_seq) < SEQ_LENGTH:\n",
        "            x_seq = [0] * (SEQ_LENGTH - len(x_seq)) + x_seq\n",
        "\n",
        "        x_seq = np.array(x_seq).reshape(1, SEQ_LENGTH)\n",
        "\n",
        "        # Predict\n",
        "        preds = model.predict(x_seq, verbose=0)[0]\n",
        "        preds = np.log(preds + 1e-7) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        # Sample\n",
        "        index = np.random.choice(len(preds), p=preds)\n",
        "        next_char = int_to_char[index]\n",
        "\n",
        "        generated += next_char\n",
        "        current_seq = current_seq[1:] + next_char\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Test generation\n",
        "print(\"Generated text:\")\n",
        "print(generate_text(\"to be or not to be\", 100))\n",
        "print(\" Training and generation completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXImGROrILz0",
        "outputId": "2154a848-1526-4b9d-ad5b-4f6718182891"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "to be or not to be doake it wondment with they you shall list our old to vs and refeauer: what one on ols not steake t\n",
            " Training and generation completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U0pGwxEoM6Vf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}